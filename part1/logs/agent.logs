time="2024-03-22T03:30:31Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:31:00Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:31:29Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:31:57Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:32:24Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:32:49Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:33:14Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:33:44Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:34:09Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to retrieve configuration from server: Get \"https://127.0.0.1:6444/v1-k3s/config\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:34:36Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:34:58Z" level=info msg="Module overlay was already loaded"
time="2024-03-22T03:34:58Z" level=info msg="Module br_netfilter was already loaded"
time="2024-03-22T03:34:58Z" level=info msg="Set sysctl 'net/ipv4/conf/all/forwarding' to 1"
time="2024-03-22T03:34:58Z" level=info msg="Set sysctl 'net/netfilter/nf_conntrack_max' to 131072"
time="2024-03-22T03:34:58Z" level=info msg="Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_established' to 86400"
time="2024-03-22T03:34:58Z" level=info msg="Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_close_wait' to 3600"
time="2024-03-22T03:34:58Z" level=info msg="Logging containerd to /var/lib/rancher/k3s/agent/containerd/containerd.log"
time="2024-03-22T03:34:58Z" level=info msg="Running containerd -c /var/lib/rancher/k3s/agent/etc/containerd/config.toml -a /run/k3s/containerd/containerd.sock --state /run/k3s/containerd --root /var/lib/rancher/k3s/agent/containerd"
time="2024-03-22T03:34:59Z" level=info msg="containerd is now running"
time="2024-03-22T03:34:59Z" level=info msg="Getting list of apiserver endpoints from server"
time="2024-03-22T03:34:59Z" level=info msg="Updated load balancer k3s-agent-load-balancer default server address -> 192.168.56.110:6443"
time="2024-03-22T03:34:59Z" level=info msg="Running kubelet --address=0.0.0.0 --allowed-unsafe-sysctls=net.ipv4.ip_forward,net.ipv6.conf.all.forwarding --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/k3s/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available<5%,nodefs.available<5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=serverworker --kubeconfig=/var/lib/rancher/k3s/agent/kubelet.kubeconfig --node-ip=192.168.56.111 --node-labels= --pod-infra-container-image=rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/k3s/agent/pod-manifests --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/k3s/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/k3s/agent/serving-kubelet.key"
time="2024-03-22T03:34:59Z" level=info msg="Connecting to proxy" url="wss://192.168.56.110:6443/v1-k3s/connect"
Flag --cloud-provider has been deprecated, will be removed in 1.25 or later, in favor of removing cloud provider code from Kubelet.
Flag --containerd has been deprecated, This is a cadvisor flag that was mistakenly registered with the Kubelet. Due to legacy concerns, it will follow the standard CLI deprecation timeline before being removed.
Flag --pod-infra-container-image has been deprecated, will be removed in a future release. Image garbage collector will get sandbox image information from CRI.
I0322 03:34:59.937064    2298 server.go:202] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
I0322 03:34:59.938907    2298 server.go:462] "Kubelet version" kubeletVersion="v1.28.7+k3s1"
I0322 03:34:59.938985    2298 server.go:464] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0322 03:34:59.940378    2298 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/agent/client-ca.crt"
I0322 03:34:59.947061    2298 server.go:720] "--cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /"
I0322 03:34:59.947670    2298 container_manager_linux.go:265] "Container manager verified user specified cgroup-root exists" cgroupRoot=[]
I0322 03:34:59.947990    2298 container_manager_linux.go:270] "Creating Container Manager object based on Node Config" nodeConfig={"RuntimeCgroupsName":"","SystemCgroupsName":"","KubeletCgroupsName":"","KubeletOOMScoreAdj":-999,"ContainerRuntime":"","CgroupsPerQOS":true,"CgroupRoot":"/","CgroupDriver":"systemd","KubeletRootDir":"/var/lib/kubelet","ProtectKernelDefaults":false,"KubeReservedCgroupName":"","SystemReservedCgroupName":"","ReservedSystemCPUs":{},"EnforceNodeAllocatable":{"pods":{}},"KubeReserved":null,"SystemReserved":null,"HardEvictionThresholds":[{"Signal":"nodefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null},{"Signal":"imagefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null}],"QOSReserved":{},"CPUManagerPolicy":"none","CPUManagerPolicyOptions":null,"TopologyManagerScope":"container","CPUManagerReconcilePeriod":10000000000,"ExperimentalMemoryManagerPolicy":"None","ExperimentalMemoryManagerReservedMemory":null,"PodPidsLimit":-1,"EnforceCPULimits":true,"CPUCFSQuotaPeriod":100000000,"TopologyManagerPolicy":"none","TopologyManagerPolicyOptions":null}
I0322 03:34:59.948033    2298 topology_manager.go:138] "Creating topology manager with none policy"
I0322 03:34:59.948077    2298 container_manager_linux.go:301] "Creating device plugin manager"
I0322 03:34:59.948211    2298 state_mem.go:36] "Initialized new in-memory state store"
I0322 03:34:59.948389    2298 kubelet.go:393] "Attempting to sync node with API server"
I0322 03:34:59.948414    2298 kubelet.go:298] "Adding static pod path" path="/var/lib/rancher/k3s/agent/pod-manifests"
I0322 03:34:59.948469    2298 kubelet.go:309] "Adding apiserver pod source"
I0322 03:34:59.948491    2298 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
I0322 03:34:59.949165    2298 kuberuntime_manager.go:257] "Container runtime initialized" containerRuntime="containerd" version="v1.7.11-k3s2" apiVersion="v1"
W0322 03:34:59.949553    2298 probe.go:268] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
I0322 03:34:59.950610    2298 server.go:1227] "Started kubelet"
E0322 03:34:59.951744    2298 cri_stats_provider.go:448] "Failed to get the info of the filesystem with mountpoint" err="unable to find data in memory cache" mountpoint="/var/lib/rancher/k3s/agent/containerd/io.containerd.snapshotter.v1.overlayfs"
E0322 03:34:59.951822    2298 kubelet.go:1431] "Image garbage collection failed once. Stats initialization may not have completed yet" err="invalid capacity 0 on image filesystem"
I0322 03:34:59.952091    2298 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
I0322 03:34:59.953952    2298 server.go:162] "Starting to listen" address="0.0.0.0" port=10250
I0322 03:34:59.954953    2298 server.go:462] "Adding debug handlers to kubelet server"
I0322 03:34:59.956815    2298 ratelimit.go:65] "Setting rate limiting for podresources endpoint" qps=100 burstTokens=10
I0322 03:34:59.957109    2298 server.go:233] "Starting to serve the podresources API" endpoint="unix:/var/lib/kubelet/pod-resources/kubelet.sock"
I0322 03:34:59.959040    2298 volume_manager.go:291] "Starting Kubelet Volume Manager"
I0322 03:34:59.959615    2298 desired_state_of_world_populator.go:151] "Desired state populator starts to run"
I0322 03:34:59.959761    2298 reconciler_new.go:29] "Reconciler: start to sync state"
E0322 03:35:00.045646    2298 nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"serverworker\" not found" node="serverworker"
I0322 03:35:00.056362    2298 cpu_manager.go:214] "Starting CPU manager" policy="none"
I0322 03:35:00.056381    2298 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
I0322 03:35:00.056394    2298 state_mem.go:36] "Initialized new in-memory state store"
I0322 03:35:00.057263    2298 policy_none.go:49] "None policy: Start"
I0322 03:35:00.057735    2298 memory_manager.go:169] "Starting memorymanager" policy="None"
I0322 03:35:00.057758    2298 state_mem.go:35] "Initializing new in-memory state store"
I0322 03:35:00.060252    2298 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
I0322 03:35:00.060972    2298 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv4"
I0322 03:35:00.099611    2298 manager.go:471] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
I0322 03:35:00.099959    2298 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
E0322 03:35:00.101738    2298 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
I0322 03:35:00.167549    2298 kubelet_node_status.go:73] "Successfully registered node" node="serverworker"
I0322 03:35:00.173095    2298 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv6"
I0322 03:35:00.173198    2298 status_manager.go:217] "Starting to sync pod status with apiserver"
I0322 03:35:00.173262    2298 kubelet.go:2303] "Starting kubelet main sync loop"
E0322 03:35:00.173367    2298 kubelet.go:2327] "Skipping pod synchronization" err="PLEG is not healthy: pleg has yet to be successful"
time="2024-03-22T03:35:00Z" level=info msg="Annotations and labels have been set successfully on node: serverworker"
time="2024-03-22T03:35:00Z" level=info msg="Starting flannel with backend vxlan"
time="2024-03-22T03:35:00Z" level=info msg="Flannel found PodCIDR assigned for node serverworker"
time="2024-03-22T03:35:00Z" level=info msg="The interface enp0s3 with ipv4 address 10.0.2.15 will be used by flannel"
I0322 03:35:00.684362    2298 kube.go:139] Waiting 10m0s for node controller to sync
I0322 03:35:00.684497    2298 kube.go:461] Starting kube subnet manager
I0322 03:35:00.949508    2298 apiserver.go:52] "Watching apiserver"
time="2024-03-22T03:35:02Z" level=info msg="Running kube-proxy --cluster-cidr=10.42.0.0/16 --conntrack-max-per-core=0 --conntrack-tcp-timeout-close-wait=0s --conntrack-tcp-timeout-established=0s --healthz-bind-address=127.0.0.1 --hostname-override=serverworker --kubeconfig=/var/lib/rancher/k3s/agent/kubeproxy.kubeconfig --proxy-mode=iptables"
I0322 03:35:03.536901    2298 kube.go:482] Creating the node lease for IPv4. This is the n.Spec.PodCIDRs: [10.42.0.0/24]
I0322 03:35:03.560439    2298 desired_state_of_world_populator.go:159] "Finished populating initial desired state of world"
I0322 03:35:03.685474    2298 kube.go:146] Node controller sync successful
I0322 03:35:03.685762    2298 vxlan.go:141] VXLAN config: VNI=1 Port=0 GBP=false Learning=false DirectRouting=false
I0322 03:35:04.418898    2298 node.go:141] Successfully retrieved node IP: 192.168.56.111
I0322 03:35:04.424378    2298 kube.go:621] List of node(serverworker) annotations: map[string]string{"alpha.kubernetes.io/provided-node-ip":"192.168.56.111", "k3s.io/hostname":"serverworker", "k3s.io/internal-ip":"192.168.56.111", "k3s.io/node-args":"[\"agent\",\"--server\",\"https://192.168.56.110:6443\",\"--token-file\",\"/vagrant/provision/token\",\"--node-ip\",\"192.168.56.111\",\"--log\",\"/vagrant/logs/agent.logs\"]", "k3s.io/node-config-hash":"YEJVE25BLELMUPKU6DR5NCCNF5THAXBIIU55LWYRIMCEB5QXNKOA====", "k3s.io/node-env":"{\"K3S_DATA_DIR\":\"/var/lib/rancher/k3s/data/a3b46c0299091b71bfcc617b1e1fec1845c13bdd848584ceb39d2e700e702a4b\"}", "node.alpha.kubernetes.io/ttl":"0", "volumes.kubernetes.io/controller-managed-attach-detach":"true"}
I0322 03:35:04.425167    2298 kuberuntime_manager.go:1528] "Updating runtime config through cri with podcidr" CIDR="10.42.1.0/24"
I0322 03:35:04.425900    2298 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.42.1.0/24"
I0322 03:35:04.426935    2298 server.go:632] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0322 03:35:04.429002    2298 server_others.go:152] "Using iptables Proxier"
I0322 03:35:04.429061    2298 server_others.go:421] "Detect-local-mode set to ClusterCIDR, but no cluster CIDR for family" ipFamily="IPv6"
I0322 03:35:04.429075    2298 server_others.go:438] "Defaulting to no-op detect-local"
I0322 03:35:04.429162    2298 proxier.go:250] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0322 03:35:04.429477    2298 server.go:846] "Version info" version="v1.28.7+k3s1"
I0322 03:35:04.429496    2298 server.go:848] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0322 03:35:04.433581    2298 config.go:188] "Starting service config controller"
I0322 03:35:04.433608    2298 shared_informer.go:311] Waiting for caches to sync for service config
I0322 03:35:04.433628    2298 config.go:97] "Starting endpoint slice config controller"
I0322 03:35:04.433633    2298 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0322 03:35:04.434293    2298 config.go:315] "Starting node config controller"
I0322 03:35:04.434311    2298 shared_informer.go:311] Waiting for caches to sync for node config
I0322 03:35:04.886795    2298 kubelet_node_status.go:493] "Fast updating node status as it just became ready"
I0322 03:35:04.934455    2298 shared_informer.go:318] Caches are synced for node config
I0322 03:35:04.934456    2298 shared_informer.go:318] Caches are synced for service config
I0322 03:35:04.934492    2298 shared_informer.go:318] Caches are synced for endpoint slice config
I0322 03:35:05.042963    2298 kube.go:482] Creating the node lease for IPv4. This is the n.Spec.PodCIDRs: [10.42.1.0/24]
time="2024-03-22T03:35:05Z" level=info msg="Wrote flannel subnet file to /run/flannel/subnet.env"
time="2024-03-22T03:35:05Z" level=info msg="Running flannel backend."
I0322 03:35:05.056208    2298 vxlan_network.go:65] watching for new subnet leases
I0322 03:35:05.056250    2298 subnet.go:160] Batch elem [0] is { lease.Event{Type:0, Lease:lease.Lease{EnableIPv4:true, EnableIPv6:false, Subnet:ip.IP4Net{IP:0xa2a0000, PrefixLen:0x18}, IPv6Subnet:ip.IP6Net{IP:(*ip.IP6)(nil), PrefixLen:0x0}, Attrs:lease.LeaseAttrs{PublicIP:0xa00020f, PublicIPv6:(*ip.IP6)(nil), BackendType:"vxlan", BackendData:json.RawMessage{0x7b, 0x22, 0x56, 0x4e, 0x49, 0x22, 0x3a, 0x31, 0x2c, 0x22, 0x56, 0x74, 0x65, 0x70, 0x4d, 0x41, 0x43, 0x22, 0x3a, 0x22, 0x31, 0x61, 0x3a, 0x33, 0x64, 0x3a, 0x30, 0x62, 0x3a, 0x63, 0x36, 0x3a, 0x35, 0x65, 0x3a, 0x65, 0x33, 0x22, 0x7d}, BackendV6Data:json.RawMessage(nil)}, Expiration:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Asof:0}} }
I0322 03:35:05.056526    2298 iptables.go:290] generated 3 rules
I0322 03:35:05.057641    2298 iptables.go:290] generated 7 rules
I0322 03:35:05.101297    2298 iptables.go:283] bootstrap done
I0322 03:35:05.123755    2298 iptables.go:283] bootstrap done
time="2024-03-22T03:35:08Z" level=info msg="Tunnel authorizer set Kubelet Port 10250"
W0322 03:35:23.024030    2298 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 03:35:23.024190    2298 nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="Get \"https://127.0.0.1:6444/api/v1/nodes/serverworker?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" node="serverworker"
W0322 03:35:24.467813    2298 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 03:35:24.468134    2298 kubelet_node_status.go:540] "Error updating node status, will retry" err="error getting node \"serverworker\": Get \"https://127.0.0.1:6444/api/v1/nodes/serverworker?resourceVersion=0&timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
E0322 03:35:26.063049    2298 server.go:310] "Unable to authenticate the request due to an error" err="context canceled"
W0322 03:35:34.468581    2298 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 03:35:34.468694    2298 kubelet_node_status.go:540] "Error updating node status, will retry" err="error getting node \"serverworker\": Get \"https://127.0.0.1:6444/api/v1/nodes/serverworker?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
E0322 03:35:41.059104    2298 server.go:310] "Unable to authenticate the request due to an error" err="context canceled"
E0322 03:35:42.621382    2298 webhook.go:154] Failed to make webhook authenticator request: Post "https://127.0.0.1:6444/apis/authentication.k8s.io/v1/tokenreviews": context deadline exceeded
W0322 03:35:43.106456    2298 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 03:35:43.106614    2298 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="200ms"
W0322 03:35:44.469482    2298 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 03:35:44.469578    2298 kubelet_node_status.go:540] "Error updating node status, will retry" err="error getting node \"serverworker\": Get \"https://127.0.0.1:6444/api/v1/nodes/serverworker?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
W0322 03:35:53.307700    2298 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 03:35:53.307853    2298 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="400ms"
W0322 03:35:54.470165    2298 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 03:35:54.470305    2298 kubelet_node_status.go:540] "Error updating node status, will retry" err="error getting node \"serverworker\": Get \"https://127.0.0.1:6444/api/v1/nodes/serverworker?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)"
W0322 03:35:55.573368    2298 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.Service ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0322 03:35:55.573427    2298 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.EndpointSlice ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0322 03:35:55.573462    2298 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.Node ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0322 03:35:56.287865    2298 server.go:310] "Unable to authenticate the request due to an error" err="context canceled"
W0322 03:35:58.027419    2298 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.Service ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0322 03:35:58.027491    2298 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.Node ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0322 03:35:58.027529    2298 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.CSIDriver ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0322 03:35:58.027634    2298 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": http2: client connection lost" interval="800ms"
W0322 03:35:58.027722    2298 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.Node ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0322 03:35:58.027757    2298 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.Pod ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0322 03:35:58.027818    2298 kubelet_node_status.go:540] "Error updating node status, will retry" err="error getting node \"serverworker\": Get \"https://127.0.0.1:6444/api/v1/nodes/serverworker?timeout=10s\": http2: client connection lost"
E0322 03:35:58.027833    2298 kubelet_node_status.go:527] "Unable to update node status" err="update node status exceeds retry count"
W0322 03:35:58.027867    2298 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.RuntimeClass ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0322 03:35:58.465887    2298 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.Namespace ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0322 03:35:58.466088    2298 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.Endpoints ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0322 03:35:58.466213    2298 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.Pod ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0322 03:35:58.465968    2298 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.NetworkPolicy ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0322 03:36:06.430689    2298 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?labelSelector=%21service.kubernetes.io%2Fheadless%2C%21service.kubernetes.io%2Fservice-proxy-name&resourceVersion=672": net/http: TLS handshake timeout
I0322 03:36:06.430838    2298 trace.go:236] Trace[1809326864]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 03:35:56.429) (total time: 10001ms):
Trace[1809326864]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/services?labelSelector=%21service.kubernetes.io%2Fheadless%2C%21service.kubernetes.io%2Fservice-proxy-name&resourceVersion=672": net/http: TLS handshake timeout 10000ms (03:36:06.430)
Trace[1809326864]: [10.001029329s] [10.001029329s] END
E0322 03:36:06.430856    2298 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?labelSelector=%21service.kubernetes.io%2Fheadless%2C%21service.kubernetes.io%2Fservice-proxy-name&resourceVersion=672": net/http: TLS handshake timeout
W0322 03:36:06.615453    2298 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.EndpointSlice: Get "https://127.0.0.1:6444/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%21service.kubernetes.io%2Fheadless%2C%21service.kubernetes.io%2Fservice-proxy-name&resourceVersion=653": net/http: TLS handshake timeout
I0322 03:36:06.615896    2298 trace.go:236] Trace[697464423]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 03:35:56.612) (total time: 10003ms):
Trace[697464423]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%21service.kubernetes.io%2Fheadless%2C%21service.kubernetes.io%2Fservice-proxy-name&resourceVersion=653": net/http: TLS handshake timeout 10002ms (03:36:06.615)
Trace[697464423]: [10.003137564s] [10.003137564s] END
E0322 03:36:06.616037    2298 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: Get "https://127.0.0.1:6444/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%21service.kubernetes.io%2Fheadless%2C%21service.kubernetes.io%2Fservice-proxy-name&resourceVersion=653": net/http: TLS handshake timeout
W0322 03:36:06.698104    2298 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=689": net/http: TLS handshake timeout
I0322 03:36:06.698182    2298 trace.go:236] Trace[1695397307]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 03:35:56.696) (total time: 10001ms):
Trace[1695397307]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=689": net/http: TLS handshake timeout 10001ms (03:36:06.698)
Trace[1695397307]: [10.001303325s] [10.001303325s] END
E0322 03:36:06.698203    2298 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=689": net/http: TLS handshake timeout
E0322 03:36:08.587166    2298 webhook.go:154] Failed to make webhook authenticator request: Post "https://127.0.0.1:6444/apis/authentication.k8s.io/v1/tokenreviews": net/http: TLS handshake timeout
E0322 03:36:08.587237    2298 server.go:310] "Unable to authenticate the request due to an error" err="Post \"https://127.0.0.1:6444/apis/authentication.k8s.io/v1/tokenreviews\": net/http: TLS handshake timeout"
W0322 03:36:08.844139    2298 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 03:36:08.844479    2298 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)" interval="1.6s"
W0322 03:36:08.909051    2298 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&resourceVersion=667": net/http: TLS handshake timeout
I0322 03:36:08.909238    2298 trace.go:236] Trace[696073062]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 03:35:58.901) (total time: 10007ms):
Trace[696073062]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&resourceVersion=667": net/http: TLS handshake timeout 10007ms (03:36:08.909)
Trace[696073062]: [10.007338596s] [10.007338596s] END
E0322 03:36:08.909255    2298 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&resourceVersion=667": net/http: TLS handshake timeout
W0322 03:36:08.986078    2298 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=653": net/http: TLS handshake timeout
I0322 03:36:08.986467    2298 trace.go:236] Trace[1412955379]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 03:35:58.985) (total time: 10001ms):
Trace[1412955379]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=653": net/http: TLS handshake timeout 10001ms (03:36:08.986)
Trace[1412955379]: [10.001276042s] [10.001276042s] END
E0322 03:36:08.986546    2298 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=653": net/http: TLS handshake timeout
W0322 03:36:09.167794    2298 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=689": net/http: TLS handshake timeout
I0322 03:36:09.167956    2298 trace.go:236] Trace[1388653072]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 03:35:59.166) (total time: 10001ms):
Trace[1388653072]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=689": net/http: TLS handshake timeout 10000ms (03:36:09.167)
Trace[1388653072]: [10.001029444s] [10.001029444s] END
E0322 03:36:09.168053    2298 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=689": net/http: TLS handshake timeout
W0322 03:36:09.319639    2298 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?resourceVersion=678": net/http: TLS handshake timeout
I0322 03:36:09.319942    2298 trace.go:236] Trace[623792241]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 03:35:59.305) (total time: 10014ms):
Trace[623792241]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/pods?resourceVersion=678": net/http: TLS handshake timeout 10014ms (03:36:09.319)
Trace[623792241]: [10.014211153s] [10.014211153s] END
E0322 03:36:09.320025    2298 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?resourceVersion=678": net/http: TLS handshake timeout
W0322 03:36:09.368417    2298 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=653": net/http: TLS handshake timeout
I0322 03:36:09.368540    2298 trace.go:236] Trace[183127399]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 03:35:59.366) (total time: 10001ms):
Trace[183127399]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=653": net/http: TLS handshake timeout 10001ms (03:36:09.368)
Trace[183127399]: [10.001803279s] [10.001803279s] END
E0322 03:36:09.368563    2298 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=653": net/http: TLS handshake timeout
W0322 03:36:09.516353    2298 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Namespace: Get "https://127.0.0.1:6444/api/v1/namespaces?resourceVersion=678": net/http: TLS handshake timeout
I0322 03:36:09.516566    2298 trace.go:236] Trace[964987222]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 03:35:59.514) (total time: 10002ms):
Trace[964987222]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/namespaces?resourceVersion=678": net/http: TLS handshake timeout 10002ms (03:36:09.516)
Trace[964987222]: [10.002289951s] [10.002289951s] END
E0322 03:36:09.516672    2298 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://127.0.0.1:6444/api/v1/namespaces?resourceVersion=678": net/http: TLS handshake timeout
W0322 03:36:09.547650    2298 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=615": net/http: TLS handshake timeout
I0322 03:36:09.547859    2298 trace.go:236] Trace[860725602]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 03:35:59.541) (total time: 10006ms):
Trace[860725602]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=615": net/http: TLS handshake timeout 10006ms (03:36:09.547)
Trace[860725602]: [10.006658342s] [10.006658342s] END
E0322 03:36:09.547915    2298 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?resourceVersion=615": net/http: TLS handshake timeout
W0322 03:36:09.623416    2298 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?resourceVersion=689": net/http: TLS handshake timeout
I0322 03:36:09.623698    2298 trace.go:236] Trace[1144240451]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 03:35:59.620) (total time: 10003ms):
Trace[1144240451]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?resourceVersion=689": net/http: TLS handshake timeout 10003ms (03:36:09.623)
Trace[1144240451]: [10.003160219s] [10.003160219s] END
E0322 03:36:09.623765    2298 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?resourceVersion=689": net/http: TLS handshake timeout
W0322 03:36:09.750619    2298 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.NetworkPolicy: Get "https://127.0.0.1:6444/apis/networking.k8s.io/v1/networkpolicies?resourceVersion=687": net/http: TLS handshake timeout
I0322 03:36:09.750725    2298 trace.go:236] Trace[458163858]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 03:35:59.748) (total time: 10001ms):
Trace[458163858]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/networking.k8s.io/v1/networkpolicies?resourceVersion=687": net/http: TLS handshake timeout 10001ms (03:36:09.750)
Trace[458163858]: [10.001737305s] [10.001737305s] END
E0322 03:36:09.750745    2298 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.NetworkPolicy: failed to list *v1.NetworkPolicy: Get "https://127.0.0.1:6444/apis/networking.k8s.io/v1/networkpolicies?resourceVersion=687": net/http: TLS handshake timeout
W0322 03:36:10.030664    2298 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=649": net/http: TLS handshake timeout
I0322 03:36:10.031171    2298 trace.go:236] Trace[770074194]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 03:36:00.023) (total time: 10007ms):
Trace[770074194]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=649": net/http: TLS handshake timeout 10006ms (03:36:10.030)
Trace[770074194]: [10.00735069s] [10.00735069s] END
E0322 03:36:10.031288    2298 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Endpoints: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=649": net/http: TLS handshake timeout
W0322 03:36:18.169022    2298 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 03:36:18.169083    2298 kubelet_node_status.go:540] "Error updating node status, will retry" err="error getting node \"serverworker\": Get \"https://127.0.0.1:6444/api/v1/nodes/serverworker?resourceVersion=0&timeout=10s\": context deadline exceeded"
time="2024-03-22T03:36:18Z" level=fatal msg="unable to initialize network policy controller: failed to identify the node by NODE_NAME, hostname or --hostname-override"
time="2024-03-22T03:36:23Z" level=info msg="Starting k3s agent v1.28.7+k3s1 (051b14b2)"
time="2024-03-22T03:36:23Z" level=info msg="Adding server to load balancer k3s-agent-load-balancer: 192.168.56.110:6443"
time="2024-03-22T03:36:23Z" level=info msg="Running load balancer k3s-agent-load-balancer 127.0.0.1:6444 -> [192.168.56.110:6443] [default: 192.168.56.110:6443]"
time="2024-03-22T03:36:44Z" level=error msg="failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:37:06Z" level=error msg="failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:37:28Z" level=error msg="failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:37:50Z" level=error msg="failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:38:12Z" level=error msg="failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:38:34Z" level=error msg="failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:38:56Z" level=error msg="failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:39:13Z" level=info msg="Starting k3s agent v1.28.7+k3s1 (051b14b2)"
time="2024-03-22T03:39:13Z" level=info msg="Adding server to load balancer k3s-agent-load-balancer: 192.168.56.110:6443"
time="2024-03-22T03:39:13Z" level=info msg="Running load balancer k3s-agent-load-balancer 127.0.0.1:6444 -> [192.168.56.110:6443] [default: 192.168.56.110:6443]"
time="2024-03-22T03:39:24Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Get \"https://127.0.0.1:6444/v1-k3s/serving-kubelet.crt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:39:56Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to retrieve configuration from server: Get \"https://127.0.0.1:6444/v1-k3s/config\": EOF"
time="2024-03-22T03:40:03Z" level=info msg="Module overlay was already loaded"
time="2024-03-22T03:40:03Z" level=info msg="Module nf_conntrack was already loaded"
time="2024-03-22T03:40:03Z" level=info msg="Module br_netfilter was already loaded"
time="2024-03-22T03:40:03Z" level=info msg="Module iptable_nat was already loaded"
time="2024-03-22T03:40:03Z" level=info msg="Module iptable_filter was already loaded"
time="2024-03-22T03:40:03Z" level=info msg="Logging containerd to /var/lib/rancher/k3s/agent/containerd/containerd.log"
time="2024-03-22T03:40:03Z" level=info msg="Running containerd -c /var/lib/rancher/k3s/agent/etc/containerd/config.toml -a /run/k3s/containerd/containerd.sock --state /run/k3s/containerd --root /var/lib/rancher/k3s/agent/containerd"
time="2024-03-22T03:40:04Z" level=info msg="containerd is now running"
time="2024-03-22T03:40:04Z" level=info msg="Getting list of apiserver endpoints from server"
time="2024-03-22T03:40:05Z" level=info msg="Updated load balancer k3s-agent-load-balancer default server address -> 192.168.56.110:6443"
time="2024-03-22T03:40:05Z" level=info msg="Running kubelet --address=0.0.0.0 --allowed-unsafe-sysctls=net.ipv4.ip_forward,net.ipv6.conf.all.forwarding --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/k3s/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available<5%,nodefs.available<5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=serverworker --kubeconfig=/var/lib/rancher/k3s/agent/kubelet.kubeconfig --node-ip=192.168.56.111 --node-labels= --pod-infra-container-image=rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/k3s/agent/pod-manifests --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/k3s/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/k3s/agent/serving-kubelet.key"
time="2024-03-22T03:40:05Z" level=info msg="Connecting to proxy" url="wss://192.168.56.110:6443/v1-k3s/connect"
Flag --cloud-provider has been deprecated, will be removed in 1.25 or later, in favor of removing cloud provider code from Kubelet.
Flag --containerd has been deprecated, This is a cadvisor flag that was mistakenly registered with the Kubelet. Due to legacy concerns, it will follow the standard CLI deprecation timeline before being removed.
Flag --pod-infra-container-image has been deprecated, will be removed in a future release. Image garbage collector will get sandbox image information from CRI.
I0322 03:40:05.079802    3327 server.go:202] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
I0322 03:40:05.081385    3327 server.go:462] "Kubelet version" kubeletVersion="v1.28.7+k3s1"
I0322 03:40:05.081405    3327 server.go:464] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0322 03:40:05.082634    3327 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/agent/client-ca.crt"
I0322 03:40:05.088502    3327 server.go:720] "--cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /"
time="2024-03-22T03:40:05Z" level=info msg="Annotations and labels have already set on node: serverworker"
I0322 03:40:05.089333    3327 container_manager_linux.go:265] "Container manager verified user specified cgroup-root exists" cgroupRoot=[]
I0322 03:40:05.089822    3327 container_manager_linux.go:270] "Creating Container Manager object based on Node Config" nodeConfig={"RuntimeCgroupsName":"","SystemCgroupsName":"","KubeletCgroupsName":"","KubeletOOMScoreAdj":-999,"ContainerRuntime":"","CgroupsPerQOS":true,"CgroupRoot":"/","CgroupDriver":"systemd","KubeletRootDir":"/var/lib/kubelet","ProtectKernelDefaults":false,"KubeReservedCgroupName":"","SystemReservedCgroupName":"","ReservedSystemCPUs":{},"EnforceNodeAllocatable":{"pods":{}},"KubeReserved":null,"SystemReserved":null,"HardEvictionThresholds":[{"Signal":"imagefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null},{"Signal":"nodefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null}],"QOSReserved":{},"CPUManagerPolicy":"none","CPUManagerPolicyOptions":null,"TopologyManagerScope":"container","CPUManagerReconcilePeriod":10000000000,"ExperimentalMemoryManagerPolicy":"None","ExperimentalMemoryManagerReservedMemory":null,"PodPidsLimit":-1,"EnforceCPULimits":true,"CPUCFSQuotaPeriod":100000000,"TopologyManagerPolicy":"none","TopologyManagerPolicyOptions":null}
I0322 03:40:05.089957    3327 topology_manager.go:138] "Creating topology manager with none policy"
I0322 03:40:05.090052    3327 container_manager_linux.go:301] "Creating device plugin manager"
I0322 03:40:05.090221    3327 state_mem.go:36] "Initialized new in-memory state store"
I0322 03:40:05.090573    3327 kubelet.go:393] "Attempting to sync node with API server"
I0322 03:40:05.090677    3327 kubelet.go:298] "Adding static pod path" path="/var/lib/rancher/k3s/agent/pod-manifests"
I0322 03:40:05.090767    3327 kubelet.go:309] "Adding apiserver pod source"
I0322 03:40:05.090892    3327 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
I0322 03:40:05.091599    3327 kuberuntime_manager.go:257] "Container runtime initialized" containerRuntime="containerd" version="v1.7.11-k3s2" apiVersion="v1"
I0322 03:40:05.092037    3327 server.go:1227] "Started kubelet"
I0322 03:40:05.093404    3327 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
E0322 03:40:05.094846    3327 cri_stats_provider.go:448] "Failed to get the info of the filesystem with mountpoint" err="unable to find data in memory cache" mountpoint="/var/lib/rancher/k3s/agent/containerd/io.containerd.snapshotter.v1.overlayfs"
E0322 03:40:05.094885    3327 kubelet.go:1431] "Image garbage collection failed once. Stats initialization may not have completed yet" err="invalid capacity 0 on image filesystem"
I0322 03:40:05.096315    3327 server.go:162] "Starting to listen" address="0.0.0.0" port=10250
I0322 03:40:05.097096    3327 server.go:462] "Adding debug handlers to kubelet server"
I0322 03:40:05.098083    3327 ratelimit.go:65] "Setting rate limiting for podresources endpoint" qps=100 burstTokens=10
I0322 03:40:05.098208    3327 server.go:233] "Starting to serve the podresources API" endpoint="unix:/var/lib/kubelet/pod-resources/kubelet.sock"
I0322 03:40:05.100015    3327 volume_manager.go:291] "Starting Kubelet Volume Manager"
I0322 03:40:05.100340    3327 desired_state_of_world_populator.go:151] "Desired state populator starts to run"
I0322 03:40:05.100415    3327 reconciler_new.go:29] "Reconciler: start to sync state"
time="2024-03-22T03:40:05Z" level=info msg="Starting flannel with backend vxlan"
I0322 03:40:05.135146    3327 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv4"
I0322 03:40:05.136375    3327 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv6"
I0322 03:40:05.136395    3327 status_manager.go:217] "Starting to sync pod status with apiserver"
I0322 03:40:05.136411    3327 kubelet.go:2303] "Starting kubelet main sync loop"
E0322 03:40:05.136453    3327 kubelet.go:2327] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
I0322 03:40:05.188700    3327 cpu_manager.go:214] "Starting CPU manager" policy="none"
I0322 03:40:05.188732    3327 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
I0322 03:40:05.188750    3327 state_mem.go:36] "Initialized new in-memory state store"
I0322 03:40:05.188956    3327 state_mem.go:88] "Updated default CPUSet" cpuSet=""
I0322 03:40:05.188974    3327 state_mem.go:96] "Updated CPUSet assignments" assignments={}
I0322 03:40:05.188979    3327 policy_none.go:49] "None policy: Start"
I0322 03:40:05.189813    3327 memory_manager.go:169] "Starting memorymanager" policy="None"
I0322 03:40:05.189978    3327 state_mem.go:35] "Initializing new in-memory state store"
I0322 03:40:05.190559    3327 state_mem.go:75] "Updated machine memory state"
I0322 03:40:05.197669    3327 manager.go:471] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
I0322 03:40:05.197983    3327 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
I0322 03:40:05.201306    3327 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
time="2024-03-22T03:40:05Z" level=info msg="Flannel found PodCIDR assigned for node serverworker"
time="2024-03-22T03:40:05Z" level=info msg="The interface enp0s3 with ipv4 address 10.0.2.15 will be used by flannel"
I0322 03:40:05.253770    3327 kube.go:139] Waiting 10m0s for node controller to sync
I0322 03:40:05.253793    3327 kube.go:461] Starting kube subnet manager
I0322 03:40:05.288495    3327 kube.go:482] Creating the node lease for IPv4. This is the n.Spec.PodCIDRs: [10.42.0.0/24]
I0322 03:40:05.288532    3327 kube.go:482] Creating the node lease for IPv4. This is the n.Spec.PodCIDRs: [10.42.1.0/24]
I0322 03:40:05.480681    3327 kubelet_node_status.go:108] "Node was previously registered" node="serverworker"
I0322 03:40:05.480967    3327 kubelet_node_status.go:73] "Successfully registered node" node="serverworker"
I0322 03:40:05.503040    3327 kuberuntime_manager.go:1528] "Updating runtime config through cri with podcidr" CIDR="10.42.1.0/24"
I0322 03:40:05.503799    3327 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.42.1.0/24"
time="2024-03-22T03:40:05Z" level=info msg="Starting network policy controller version v2.0.1, built on 2024-02-29T20:36:21Z, go1.21.7"
I0322 03:40:05.509630    3327 network_policy_controller.go:164] Starting network policy controller
I0322 03:40:05.547154    3327 network_policy_controller.go:176] Starting network policy controller full sync goroutine
time="2024-03-22T03:40:05Z" level=info msg="Running kube-proxy --cluster-cidr=10.42.0.0/16 --conntrack-max-per-core=0 --conntrack-tcp-timeout-close-wait=0s --conntrack-tcp-timeout-established=0s --healthz-bind-address=127.0.0.1 --hostname-override=serverworker --kubeconfig=/var/lib/rancher/k3s/agent/kubeproxy.kubeconfig --proxy-mode=iptables"
I0322 03:40:05.606744    3327 node.go:141] Successfully retrieved node IP: 192.168.56.111
I0322 03:40:05.611375    3327 server.go:632] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0322 03:40:05.613218    3327 server_others.go:152] "Using iptables Proxier"
I0322 03:40:05.613245    3327 server_others.go:421] "Detect-local-mode set to ClusterCIDR, but no cluster CIDR for family" ipFamily="IPv6"
I0322 03:40:05.613251    3327 server_others.go:438] "Defaulting to no-op detect-local"
I0322 03:40:05.613270    3327 proxier.go:250] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0322 03:40:05.613378    3327 server.go:846] "Version info" version="v1.28.7+k3s1"
I0322 03:40:05.613386    3327 server.go:848] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0322 03:40:05.616096    3327 config.go:188] "Starting service config controller"
I0322 03:40:05.616110    3327 shared_informer.go:311] Waiting for caches to sync for service config
I0322 03:40:05.616121    3327 config.go:97] "Starting endpoint slice config controller"
I0322 03:40:05.616126    3327 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0322 03:40:05.616370    3327 config.go:315] "Starting node config controller"
I0322 03:40:05.616377    3327 shared_informer.go:311] Waiting for caches to sync for node config
I0322 03:40:05.716565    3327 shared_informer.go:318] Caches are synced for node config
I0322 03:40:05.716595    3327 shared_informer.go:318] Caches are synced for service config
I0322 03:40:05.716634    3327 shared_informer.go:318] Caches are synced for endpoint slice config
time="2024-03-22T03:40:05Z" level=info msg="Tunnel authorizer set Kubelet Port 10250"
I0322 03:40:06.093617    3327 apiserver.go:52] "Watching apiserver"
I0322 03:40:06.201612    3327 desired_state_of_world_populator.go:159] "Finished populating initial desired state of world"
I0322 03:40:06.254604    3327 kube.go:146] Node controller sync successful
I0322 03:40:06.255116    3327 vxlan.go:141] VXLAN config: VNI=1 Port=0 GBP=false Learning=false DirectRouting=false
I0322 03:40:06.268609    3327 kube.go:621] List of node(serverworker) annotations: map[string]string{"alpha.kubernetes.io/provided-node-ip":"192.168.56.111", "flannel.alpha.coreos.com/backend-data":"{\"VNI\":1,\"VtepMAC\":\"66:9c:f0:a6:c2:40\"}", "flannel.alpha.coreos.com/backend-type":"vxlan", "flannel.alpha.coreos.com/kube-subnet-manager":"true", "flannel.alpha.coreos.com/public-ip":"10.0.2.15", "k3s.io/hostname":"serverworker", "k3s.io/internal-ip":"192.168.56.111", "k3s.io/node-args":"[\"agent\",\"--server\",\"https://192.168.56.110:6443\",\"--token-file\",\"/vagrant/provision/token\",\"--node-ip\",\"192.168.56.111\",\"--log\",\"/vagrant/logs/agent.logs\"]", "k3s.io/node-config-hash":"YEJVE25BLELMUPKU6DR5NCCNF5THAXBIIU55LWYRIMCEB5QXNKOA====", "k3s.io/node-env":"{\"K3S_DATA_DIR\":\"/var/lib/rancher/k3s/data/a3b46c0299091b71bfcc617b1e1fec1845c13bdd848584ceb39d2e700e702a4b\"}", "node.alpha.kubernetes.io/ttl":"0", "volumes.kubernetes.io/controller-managed-attach-detach":"true"}
I0322 03:40:06.268835    3327 vxlan.go:155] Setup flannel.1 mac address to 66:9c:f0:a6:c2:40 when flannel restarts
time="2024-03-22T03:40:06Z" level=info msg="Wrote flannel subnet file to /run/flannel/subnet.env"
time="2024-03-22T03:40:06Z" level=info msg="Running flannel backend."
I0322 03:40:06.301333    3327 vxlan_network.go:65] watching for new subnet leases
I0322 03:40:06.301384    3327 subnet.go:160] Batch elem [0] is { lease.Event{Type:0, Lease:lease.Lease{EnableIPv4:true, EnableIPv6:false, Subnet:ip.IP4Net{IP:0xa2a0000, PrefixLen:0x18}, IPv6Subnet:ip.IP6Net{IP:(*ip.IP6)(nil), PrefixLen:0x0}, Attrs:lease.LeaseAttrs{PublicIP:0xa00020f, PublicIPv6:(*ip.IP6)(nil), BackendType:"vxlan", BackendData:json.RawMessage{0x7b, 0x22, 0x56, 0x4e, 0x49, 0x22, 0x3a, 0x31, 0x2c, 0x22, 0x56, 0x74, 0x65, 0x70, 0x4d, 0x41, 0x43, 0x22, 0x3a, 0x22, 0x31, 0x61, 0x3a, 0x33, 0x64, 0x3a, 0x30, 0x62, 0x3a, 0x63, 0x36, 0x3a, 0x35, 0x65, 0x3a, 0x65, 0x33, 0x22, 0x7d}, BackendV6Data:json.RawMessage(nil)}, Expiration:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Asof:0}} }
I0322 03:40:06.301580    3327 iptables.go:290] generated 3 rules
I0322 03:40:06.307558    3327 iptables.go:290] generated 7 rules
I0322 03:40:06.324673    3327 iptables.go:283] bootstrap done
I0322 03:40:06.338013    3327 iptables.go:283] bootstrap done
I0322 03:40:13.261979    3327 topology_manager.go:215] "Topology Admit Handler" podUID="8e9642db-4604-47e2-8f71-29d5e4f049ae" podNamespace="kube-system" podName="svclb-traefik-ae8f6f60-8p2ds"
I0322 03:40:13.370348    3327 topology_manager.go:215] "Topology Admit Handler" podUID="d6704f4a-15ff-4ad7-beeb-a6e3347c6ff0" podNamespace="kube-system" podName="traefik-f4564c4f4-vcw4k"
I0322 03:40:13.409909    3327 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"data\" (UniqueName: \"kubernetes.io/empty-dir/d6704f4a-15ff-4ad7-beeb-a6e3347c6ff0-data\") pod \"traefik-f4564c4f4-vcw4k\" (UID: \"d6704f4a-15ff-4ad7-beeb-a6e3347c6ff0\") " pod="kube-system/traefik-f4564c4f4-vcw4k"
I0322 03:40:13.410136    3327 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp\" (UniqueName: \"kubernetes.io/empty-dir/d6704f4a-15ff-4ad7-beeb-a6e3347c6ff0-tmp\") pod \"traefik-f4564c4f4-vcw4k\" (UID: \"d6704f4a-15ff-4ad7-beeb-a6e3347c6ff0\") " pod="kube-system/traefik-f4564c4f4-vcw4k"
I0322 03:40:13.410319    3327 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-92rcn\" (UniqueName: \"kubernetes.io/projected/d6704f4a-15ff-4ad7-beeb-a6e3347c6ff0-kube-api-access-92rcn\") pod \"traefik-f4564c4f4-vcw4k\" (UID: \"d6704f4a-15ff-4ad7-beeb-a6e3347c6ff0\") " pod="kube-system/traefik-f4564c4f4-vcw4k"
I0322 03:40:23.591412    3327 kuberuntime_container_linux.go:167] "No swap cgroup controller present" swapBehavior="" pod="kube-system/svclb-traefik-ae8f6f60-8p2ds" containerName="lb-tcp-80"
I0322 03:40:23.764609    3327 kuberuntime_container_linux.go:167] "No swap cgroup controller present" swapBehavior="" pod="kube-system/svclb-traefik-ae8f6f60-8p2ds" containerName="lb-tcp-443"
I0322 03:40:24.317344    3327 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/svclb-traefik-ae8f6f60-8p2ds" podStartSLOduration=4.124712639 podCreationTimestamp="2024-03-22 03:40:13 +0000 UTC" firstStartedPulling="2024-03-22 03:40:16.397242966 +0000 UTC m=+63.320481793" lastFinishedPulling="2024-03-22 03:40:23.589635327 +0000 UTC m=+70.512874162" observedRunningTime="2024-03-22 03:40:24.315932296 +0000 UTC m=+71.239171175" watchObservedRunningTime="2024-03-22 03:40:24.317105008 +0000 UTC m=+71.240343868"
I0322 03:40:28.624823    3327 kuberuntime_container_linux.go:167] "No swap cgroup controller present" swapBehavior="" pod="kube-system/traefik-f4564c4f4-vcw4k" containerName="traefik"
I0322 03:40:30.341441    3327 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/traefik-f4564c4f4-vcw4k" podStartSLOduration=5.029736574 podCreationTimestamp="2024-03-22 03:40:13 +0000 UTC" firstStartedPulling="2024-03-22 03:40:16.311158506 +0000 UTC m=+63.234397339" lastFinishedPulling="2024-03-22 03:40:28.622774522 +0000 UTC m=+75.546013361" observedRunningTime="2024-03-22 03:40:29.300265825 +0000 UTC m=+76.223504671" watchObservedRunningTime="2024-03-22 03:40:30.341352596 +0000 UTC m=+77.264591454"
time="2024-03-22T03:54:59Z" level=info msg="Starting k3s agent v1.28.7+k3s1 (051b14b2)"
time="2024-03-22T03:54:59Z" level=info msg="Adding server to load balancer k3s-agent-load-balancer: 192.168.56.110:6443"
time="2024-03-22T03:54:59Z" level=info msg="Running load balancer k3s-agent-load-balancer 127.0.0.1:6444 -> [192.168.56.110:6443] [default: 192.168.56.110:6443]"
time="2024-03-22T03:55:10Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Get \"https://127.0.0.1:6444/v1-k3s/serving-kubelet.crt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:55:40Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:56:06Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:56:32Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:56:59Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:57:27Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:57:54Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:58:19Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:58:49Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:59:18Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T03:59:47Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T04:00:25Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Get \"https://127.0.0.1:6444/v1-k3s/serving-kubelet.crt\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
time="2024-03-22T04:00:36Z" level=info msg="Module overlay was already loaded"
time="2024-03-22T04:00:36Z" level=info msg="Module br_netfilter was already loaded"
time="2024-03-22T04:00:36Z" level=info msg="Set sysctl 'net/netfilter/nf_conntrack_max' to 131072"
time="2024-03-22T04:00:36Z" level=info msg="Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_established' to 86400"
time="2024-03-22T04:00:36Z" level=info msg="Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_close_wait' to 3600"
time="2024-03-22T04:00:36Z" level=info msg="Set sysctl 'net/ipv4/conf/all/forwarding' to 1"
time="2024-03-22T04:00:36Z" level=info msg="Logging containerd to /var/lib/rancher/k3s/agent/containerd/containerd.log"
time="2024-03-22T04:00:36Z" level=info msg="Running containerd -c /var/lib/rancher/k3s/agent/etc/containerd/config.toml -a /run/k3s/containerd/containerd.sock --state /run/k3s/containerd --root /var/lib/rancher/k3s/agent/containerd"
time="2024-03-22T04:00:37Z" level=info msg="containerd is now running"
time="2024-03-22T04:00:37Z" level=info msg="Getting list of apiserver endpoints from server"
time="2024-03-22T04:00:38Z" level=info msg="Updated load balancer k3s-agent-load-balancer default server address -> 192.168.56.110:6443"
time="2024-03-22T04:00:38Z" level=info msg="Running kubelet --address=0.0.0.0 --allowed-unsafe-sysctls=net.ipv4.ip_forward,net.ipv6.conf.all.forwarding --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=systemd --client-ca-file=/var/lib/rancher/k3s/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available<5%,nodefs.available<5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --feature-gates=CloudDualStackNodeIPs=true --healthz-bind-address=127.0.0.1 --hostname-override=serverworker --kubeconfig=/var/lib/rancher/k3s/agent/kubelet.kubeconfig --node-ip=192.168.56.111 --node-labels= --pod-infra-container-image=rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/k3s/agent/pod-manifests --read-only-port=0 --resolv-conf=/run/systemd/resolve/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/k3s/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/k3s/agent/serving-kubelet.key"
time="2024-03-22T04:00:38Z" level=info msg="Connecting to proxy" url="wss://192.168.56.110:6443/v1-k3s/connect"
Flag --cloud-provider has been deprecated, will be removed in 1.25 or later, in favor of removing cloud provider code from Kubelet.
Flag --containerd has been deprecated, This is a cadvisor flag that was mistakenly registered with the Kubelet. Due to legacy concerns, it will follow the standard CLI deprecation timeline before being removed.
Flag --pod-infra-container-image has been deprecated, will be removed in a future release. Image garbage collector will get sandbox image information from CRI.
I0322 04:00:38.211934    2337 server.go:202] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
I0322 04:00:38.213857    2337 server.go:462] "Kubelet version" kubeletVersion="v1.28.7+k3s1"
I0322 04:00:38.213879    2337 server.go:464] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0322 04:00:38.215938    2337 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/agent/client-ca.crt"
I0322 04:00:38.221930    2337 server.go:720] "--cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /"
I0322 04:00:38.222670    2337 container_manager_linux.go:265] "Container manager verified user specified cgroup-root exists" cgroupRoot=[]
I0322 04:00:38.223118    2337 container_manager_linux.go:270] "Creating Container Manager object based on Node Config" nodeConfig={"RuntimeCgroupsName":"","SystemCgroupsName":"","KubeletCgroupsName":"","KubeletOOMScoreAdj":-999,"ContainerRuntime":"","CgroupsPerQOS":true,"CgroupRoot":"/","CgroupDriver":"systemd","KubeletRootDir":"/var/lib/kubelet","ProtectKernelDefaults":false,"KubeReservedCgroupName":"","SystemReservedCgroupName":"","ReservedSystemCPUs":{},"EnforceNodeAllocatable":{"pods":{}},"KubeReserved":null,"SystemReserved":null,"HardEvictionThresholds":[{"Signal":"imagefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null},{"Signal":"nodefs.available","Operator":"LessThan","Value":{"Quantity":null,"Percentage":0.05},"GracePeriod":0,"MinReclaim":null}],"QOSReserved":{},"CPUManagerPolicy":"none","CPUManagerPolicyOptions":null,"TopologyManagerScope":"container","CPUManagerReconcilePeriod":10000000000,"ExperimentalMemoryManagerPolicy":"None","ExperimentalMemoryManagerReservedMemory":null,"PodPidsLimit":-1,"EnforceCPULimits":true,"CPUCFSQuotaPeriod":100000000,"TopologyManagerPolicy":"none","TopologyManagerPolicyOptions":null}
I0322 04:00:38.223293    2337 topology_manager.go:138] "Creating topology manager with none policy"
I0322 04:00:38.223438    2337 container_manager_linux.go:301] "Creating device plugin manager"
I0322 04:00:38.223658    2337 state_mem.go:36] "Initialized new in-memory state store"
I0322 04:00:38.223974    2337 kubelet.go:393] "Attempting to sync node with API server"
I0322 04:00:38.224096    2337 kubelet.go:298] "Adding static pod path" path="/var/lib/rancher/k3s/agent/pod-manifests"
I0322 04:00:38.224226    2337 kubelet.go:309] "Adding apiserver pod source"
I0322 04:00:38.224348    2337 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
I0322 04:00:38.225093    2337 kuberuntime_manager.go:257] "Container runtime initialized" containerRuntime="containerd" version="v1.7.11-k3s2" apiVersion="v1"
W0322 04:00:38.225467    2337 probe.go:268] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
I0322 04:00:38.226577    2337 server.go:1227] "Started kubelet"
I0322 04:00:38.228633    2337 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
I0322 04:00:38.231969    2337 volume_manager.go:291] "Starting Kubelet Volume Manager"
I0322 04:00:38.228682    2337 ratelimit.go:65] "Setting rate limiting for podresources endpoint" qps=100 burstTokens=10
I0322 04:00:38.232293    2337 server.go:233] "Starting to serve the podresources API" endpoint="unix:/var/lib/kubelet/pod-resources/kubelet.sock"
I0322 04:00:38.228735    2337 server.go:162] "Starting to listen" address="0.0.0.0" port=10250
I0322 04:00:38.233215    2337 server.go:462] "Adding debug handlers to kubelet server"
I0322 04:00:38.234059    2337 desired_state_of_world_populator.go:151] "Desired state populator starts to run"
I0322 04:00:38.234913    2337 reconciler_new.go:29] "Reconciler: start to sync state"
E0322 04:00:38.228978    2337 cri_stats_provider.go:448] "Failed to get the info of the filesystem with mountpoint" err="unable to find data in memory cache" mountpoint="/var/lib/rancher/k3s/agent/containerd/io.containerd.snapshotter.v1.overlayfs"
E0322 04:00:38.234962    2337 kubelet.go:1431] "Image garbage collection failed once. Stats initialization may not have completed yet" err="invalid capacity 0 on image filesystem"
E0322 04:00:38.235806    2337 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"serverworker\" not found"
I0322 04:00:38.325091    2337 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv4"
I0322 04:00:38.337459    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
I0322 04:00:38.337519    2337 cpu_manager.go:214] "Starting CPU manager" policy="none"
I0322 04:00:38.337703    2337 cpu_manager.go:215] "Reconciling" reconcilePeriod="10s"
I0322 04:00:38.337728    2337 state_mem.go:36] "Initialized new in-memory state store"
I0322 04:00:38.339000    2337 policy_none.go:49] "None policy: Start"
I0322 04:00:38.339711    2337 memory_manager.go:169] "Starting memorymanager" policy="None"
I0322 04:00:38.339753    2337 state_mem.go:35] "Initializing new in-memory state store"
I0322 04:00:38.346441    2337 kubelet_network_linux.go:50] "Initialized iptables rules." protocol="IPv6"
I0322 04:00:38.346474    2337 status_manager.go:217] "Starting to sync pod status with apiserver"
I0322 04:00:38.346492    2337 kubelet.go:2303] "Starting kubelet main sync loop"
E0322 04:00:38.346546    2337 kubelet.go:2327] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
W0322 04:00:38.370523    2337 watcher.go:93] Error while processing event ("/sys/fs/cgroup/devices/kubepods.slice/kubepods-besteffort.slice": 0x40000100 == IN_CREATE|IN_ISDIR): inotify_add_watch /sys/fs/cgroup/devices/kubepods.slice/kubepods-besteffort.slice: no such file or directory
I0322 04:00:38.371288    2337 manager.go:471] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
I0322 04:00:38.371534    2337 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
E0322 04:00:38.373331    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
I0322 04:00:39.224895    2337 apiserver.go:52] "Watching apiserver"
W0322 04:00:48.236815    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:00:48.237161    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="200ms"
E0322 04:00:48.375849    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
time="2024-03-22T04:00:58Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to retrieve configuration from server: Get \"https://127.0.0.1:6444/v1-k3s/config\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
E0322 04:00:58.376882    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:00:58.438374    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": context deadline exceeded" interval="400ms"
E0322 04:01:08.377959    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
W0322 04:01:08.839510    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:01:08.839679    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="800ms"
E0322 04:01:18.378436    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
W0322 04:01:19.644533    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:01:19.644718    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="1.6s"
time="2024-03-22T04:01:23Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
E0322 04:01:28.378904    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:01:28.404704    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?allowWatchBookmarks=true&resourceVersion=756&timeout=8m9s&timeoutSeconds=489&watch=true": http2: client connection lost
W0322 04:01:28.404785    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": http2: client connection lost
I0322 04:01:28.404849    2337 trace.go:236] Trace[590355523]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:00:39.225) (total time: 49179ms):
Trace[590355523]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": http2: client connection lost 49179ms (04:01:28.404)
Trace[590355523]: [49.179804925s] [49.179804925s] END
E0322 04:01:28.404862    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": http2: client connection lost
E0322 04:01:28.404897    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dserverworker&resourceVersion=700&timeout=5m17s&timeoutSeconds=317&watch=true": http2: client connection lost
W0322 04:01:28.405037    2337 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.CSIDriver ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0322 04:01:28.405139    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": http2: client connection lost" interval="3.2s"
W0322 04:01:28.405183    2337 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.Node ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0322 04:01:28.405199    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": http2: client connection lost" node="serverworker"
W0322 04:01:28.405275    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": http2: client connection lost
I0322 04:01:28.405345    2337 trace.go:236] Trace[137612610]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:00:38.349) (total time: 50055ms):
Trace[137612610]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": http2: client connection lost 50055ms (04:01:28.405)
Trace[137612610]: [50.055496827s] [50.055496827s] END
E0322 04:01:28.405357    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": http2: client connection lost
E0322 04:01:28.404975    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa4c0fa65", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": http2: client connection lost'(may retry after sleeping)
I0322 04:01:28.606652    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
E0322 04:01:38.379052    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:01:38.423821    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa4c0fa65", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
E0322 04:01:38.607979    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
I0322 04:01:39.011141    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
W0322 04:01:39.253654    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:01:39.253743    2337 trace.go:236] Trace[1743327301]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:29.251) (total time: 10001ms):
Trace[1743327301]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10001ms (04:01:39.253)
Trace[1743327301]: [10.001715375s] [10.001715375s] END
E0322 04:01:39.253786    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
W0322 04:01:39.758285    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:01:39.758373    2337 trace.go:236] Trace[1968202520]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:29.750) (total time: 10008ms):
Trace[1968202520]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout 10007ms (04:01:39.758)
Trace[1968202520]: [10.008020872s] [10.008020872s] END
E0322 04:01:39.758390    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0322 04:01:39.758515    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:01:39.758705    2337 trace.go:236] Trace[1089343795]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:29.513) (total time: 10244ms):
Trace[1089343795]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10244ms (04:01:39.758)
Trace[1089343795]: [10.244970209s] [10.244970209s] END
E0322 04:01:39.758750    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0322 04:01:39.759019    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:01:39.759122    2337 trace.go:236] Trace[494634036]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:29.514) (total time: 10244ms):
Trace[494634036]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10244ms (04:01:39.759)
Trace[494634036]: [10.244127544s] [10.244127544s] END
E0322 04:01:39.759216    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
W0322 04:01:39.868526    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
I0322 04:01:39.868605    2337 trace.go:236] Trace[1756473411]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:29.866) (total time: 10002ms):
Trace[1756473411]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout 10001ms (04:01:39.868)
Trace[1756473411]: [10.002023535s] [10.002023535s] END
E0322 04:01:39.868622    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
W0322 04:01:40.017955    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
I0322 04:01:40.018429    2337 trace.go:236] Trace[882932179]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:30.005) (total time: 10013ms):
Trace[882932179]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout 10012ms (04:01:40.017)
Trace[882932179]: [10.01320139s] [10.01320139s] END
E0322 04:01:40.018532    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
E0322 04:01:41.606906    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": context deadline exceeded" interval="6.4s"
W0322 04:01:41.606943    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
time="2024-03-22T04:01:48Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
E0322 04:01:48.379478    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:01:49.022453    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
I0322 04:01:49.824453    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
W0322 04:01:51.474887    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:01:51.475151    2337 trace.go:236] Trace[756660977]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:41.473) (total time: 10001ms):
Trace[756660977]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10001ms (04:01:51.474)
Trace[756660977]: [10.001826664s] [10.001826664s] END
E0322 04:01:51.475265    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
W0322 04:01:51.829045    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:01:51.829261    2337 trace.go:236] Trace[1595596776]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:41.828) (total time: 10001ms):
Trace[1595596776]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10000ms (04:01:51.828)
Trace[1595596776]: [10.001066099s] [10.001066099s] END
E0322 04:01:51.829291    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
W0322 04:01:51.902071    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:01:51.902407    2337 trace.go:236] Trace[477490627]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:41.900) (total time: 10002ms):
Trace[477490627]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (04:01:51.902)
Trace[477490627]: [10.002141119s] [10.002141119s] END
E0322 04:01:51.902544    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0322 04:01:52.098251    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
I0322 04:01:52.098504    2337 trace.go:236] Trace[1132582742]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:42.096) (total time: 10001ms):
Trace[1132582742]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout 10001ms (04:01:52.098)
Trace[1132582742]: [10.001567157s] [10.001567157s] END
E0322 04:01:52.098615    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
W0322 04:01:52.118935    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:01:52.119160    2337 trace.go:236] Trace[431033832]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:42.118) (total time: 10001ms):
Trace[431033832]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout 10000ms (04:01:52.118)
Trace[431033832]: [10.001052674s] [10.001052674s] END
E0322 04:01:52.119269    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0322 04:01:52.379205    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
I0322 04:01:52.379472    2337 trace.go:236] Trace[1320287195]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:42.377) (total time: 10001ms):
Trace[1320287195]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout 10001ms (04:01:52.379)
Trace[1320287195]: [10.001375238s] [10.001375238s] END
E0322 04:01:52.379584    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
W0322 04:01:58.008248    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:01:58.008487    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)" interval="7s"
E0322 04:01:58.380325    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:01:58.426767    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa4c0fa65", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
E0322 04:01:59.826327    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
I0322 04:02:01.428205    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
W0322 04:02:04.794342    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:02:04.794837    2337 trace.go:236] Trace[827780617]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:54.789) (total time: 10004ms):
Trace[827780617]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10004ms (04:02:04.794)
Trace[827780617]: [10.004905383s] [10.004905383s] END
E0322 04:02:04.794985    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
W0322 04:02:06.246308    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
I0322 04:02:06.246415    2337 trace.go:236] Trace[227379794]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:56.244) (total time: 10001ms):
Trace[227379794]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout 10001ms (04:02:06.246)
Trace[227379794]: [10.001782468s] [10.001782468s] END
E0322 04:02:06.246432    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
W0322 04:02:06.735556    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
I0322 04:02:06.735779    2337 trace.go:236] Trace[855464378]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:56.733) (total time: 10002ms):
Trace[855464378]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout 10001ms (04:02:06.735)
Trace[855464378]: [10.002005238s] [10.002005238s] END
E0322 04:02:06.735890    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
W0322 04:02:07.032997    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:02:07.033314    2337 trace.go:236] Trace[1680765337]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:57.031) (total time: 10001ms):
Trace[1680765337]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10001ms (04:02:07.032)
Trace[1680765337]: [10.001871156s] [10.001871156s] END
E0322 04:02:07.033431    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
W0322 04:02:07.296303    2337 reflector.go:458] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: watch of *v1.Endpoints ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0322 04:02:08.055106    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:02:08.055351    2337 trace.go:236] Trace[1881052431]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:58.054) (total time: 10001ms):
Trace[1881052431]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10000ms (04:02:08.055)
Trace[1881052431]: [10.001024965s] [10.001024965s] END
E0322 04:02:08.055456    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0322 04:02:08.087771    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:02:08.087887    2337 trace.go:236] Trace[1202261216]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:01:58.086) (total time: 10001ms):
Trace[1202261216]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (04:02:08.087)
Trace[1202261216]: [10.00142953s] [10.00142953s] END
E0322 04:02:08.087911    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
E0322 04:02:08.381426    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:02:11.439123    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
time="2024-03-22T04:02:13Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
I0322 04:02:14.640447    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
W0322 04:02:15.010982    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:02:15.011382    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)" interval="7s"
W0322 04:02:18.360148    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
I0322 04:02:18.360373    2337 trace.go:236] Trace[892411744]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:08.358) (total time: 10001ms):
Trace[892411744]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout 10001ms (04:02:18.360)
Trace[892411744]: [10.001326509s] [10.001326509s] END
E0322 04:02:18.360459    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Endpoints: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
E0322 04:02:18.381976    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:02:18.428913    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa4c0fa65", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
W0322 04:02:21.841884    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:02:21.842357    2337 trace.go:236] Trace[1591070831]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:11.745) (total time: 10097ms):
Trace[1591070831]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10096ms (04:02:21.841)
Trace[1591070831]: [10.097247437s] [10.097247437s] END
E0322 04:02:21.842463    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
E0322 04:02:24.643895    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
W0322 04:02:24.919735    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:02:24.920013    2337 trace.go:236] Trace[673298469]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:14.914) (total time: 10005ms):
Trace[673298469]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10005ms (04:02:24.919)
Trace[673298469]: [10.005208235s] [10.005208235s] END
E0322 04:02:24.920121    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0322 04:02:25.586552    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:02:25.586828    2337 trace.go:236] Trace[1877378784]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:15.528) (total time: 10058ms):
Trace[1877378784]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10058ms (04:02:25.586)
Trace[1877378784]: [10.058699744s] [10.058699744s] END
E0322 04:02:25.586941    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
W0322 04:02:27.363424    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
I0322 04:02:27.363695    2337 trace.go:236] Trace[962258301]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:17.362) (total time: 10001ms):
Trace[962258301]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout 10001ms (04:02:27.363)
Trace[962258301]: [10.0013484s] [10.0013484s] END
E0322 04:02:27.363806    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
E0322 04:02:28.402636    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
W0322 04:02:28.514410    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
I0322 04:02:28.514646    2337 trace.go:236] Trace[1100936083]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:18.513) (total time: 10001ms):
Trace[1100936083]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout 10001ms (04:02:28.514)
Trace[1100936083]: [10.001530057s] [10.001530057s] END
E0322 04:02:28.514744    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
W0322 04:02:30.741084    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:02:30.741169    2337 trace.go:236] Trace[744003604]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:20.738) (total time: 10002ms):
Trace[744003604]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout 10002ms (04:02:30.741)
Trace[744003604]: [10.002600969s] [10.002600969s] END
E0322 04:02:30.741235    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:02:31.047672    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
W0322 04:02:31.372951    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
I0322 04:02:31.373024    2337 trace.go:236] Trace[160676338]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:21.371) (total time: 10001ms):
Trace[160676338]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout 10001ms (04:02:31.372)
Trace[160676338]: [10.001572462s] [10.001572462s] END
E0322 04:02:31.373040    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Endpoints: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
W0322 04:02:32.018217    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:02:32.018506    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)" interval="7s"
time="2024-03-22T04:02:33Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
E0322 04:02:38.404225    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:02:38.442948    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa4c0fa65", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
E0322 04:02:41.048818    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
W0322 04:02:46.299662    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
I0322 04:02:46.299744    2337 trace.go:236] Trace[472834021]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:36.297) (total time: 10001ms):
Trace[472834021]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout 10001ms (04:02:46.299)
Trace[472834021]: [10.001802985s] [10.001802985s] END
E0322 04:02:46.299782    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Endpoints: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
W0322 04:02:47.040106    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:02:47.040198    2337 trace.go:236] Trace[542058423]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:37.038) (total time: 10001ms):
Trace[542058423]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10001ms (04:02:47.040)
Trace[542058423]: [10.00140717s] [10.00140717s] END
E0322 04:02:47.040216    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:02:48.050915    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
E0322 04:02:48.404676    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
W0322 04:02:49.019277    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
W0322 04:02:49.019374    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:02:49.019463    2337 trace.go:236] Trace[1774581006]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:39.017) (total time: 10001ms):
Trace[1774581006]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10001ms (04:02:49.019)
Trace[1774581006]: [10.001487939s] [10.001487939s] END
E0322 04:02:49.019480    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
E0322 04:02:49.019655    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)" interval="7s"
W0322 04:02:50.679048    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:02:50.679357    2337 trace.go:236] Trace[1444879263]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:40.677) (total time: 10001ms):
Trace[1444879263]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (04:02:50.679)
Trace[1444879263]: [10.001703671s] [10.001703671s] END
E0322 04:02:50.679472    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0322 04:02:57.066899    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
I0322 04:02:57.067092    2337 trace.go:236] Trace[888477967]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:47.065) (total time: 10001ms):
Trace[888477967]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout 10001ms (04:02:57.066)
Trace[888477967]: [10.001472951s] [10.001472951s] END
E0322 04:02:57.067207    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
E0322 04:02:58.052042    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
time="2024-03-22T04:02:58Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
E0322 04:02:58.405199    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:02:58.449102    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa4c0fa65", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
W0322 04:02:59.067077    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
I0322 04:02:59.067177    2337 trace.go:236] Trace[919382439]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:49.060) (total time: 10006ms):
Trace[919382439]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout 10006ms (04:02:59.067)
Trace[919382439]: [10.00639125s] [10.00639125s] END
E0322 04:02:59.067197    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
W0322 04:03:00.545262    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:03:00.545569    2337 trace.go:236] Trace[949728129]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:50.543) (total time: 10002ms):
Trace[949728129]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (04:03:00.545)
Trace[949728129]: [10.002056557s] [10.002056557s] END
E0322 04:03:00.545688    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0322 04:03:04.738303    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
I0322 04:03:04.738574    2337 trace.go:236] Trace[578161726]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:02:54.737) (total time: 10001ms):
Trace[578161726]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout 10001ms (04:03:04.738)
Trace[578161726]: [10.001296552s] [10.001296552s] END
E0322 04:03:04.738678    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Endpoints: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
I0322 04:03:05.054401    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
W0322 04:03:06.026479    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:03:06.026620    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)" interval="7s"
E0322 04:03:08.409313    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:03:15.056131    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
E0322 04:03:18.410114    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:03:18.459270    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa4c0fa65", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
I0322 04:03:22.057378    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
W0322 04:03:23.027249    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:03:23.027549    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)" interval="7s"
time="2024-03-22T04:03:23Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
E0322 04:03:28.410585    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
W0322 04:03:31.182979    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
I0322 04:03:31.183064    2337 trace.go:236] Trace[204386243]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:03:21.181) (total time: 10001ms):
Trace[204386243]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout 10001ms (04:03:31.182)
Trace[204386243]: [10.001425107s] [10.001425107s] END
E0322 04:03:31.183111    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Endpoints: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
W0322 04:03:31.427566    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:03:31.427762    2337 trace.go:236] Trace[1428580095]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:03:21.425) (total time: 10001ms):
Trace[1428580095]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (04:03:31.427)
Trace[1428580095]: [10.001807848s] [10.001807848s] END
E0322 04:03:31.427785    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
E0322 04:03:32.059028    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
E0322 04:03:38.414156    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:03:38.462102    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa4c0fa65", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
I0322 04:03:39.060979    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
W0322 04:03:39.950382    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:03:39.950513    2337 trace.go:236] Trace[233693684]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:03:29.947) (total time: 10003ms):
Trace[233693684]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10003ms (04:03:39.950)
Trace[233693684]: [10.003122551s] [10.003122551s] END
E0322 04:03:39.950532    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
W0322 04:03:40.029542    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:03:40.029756    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)" interval="7s"
W0322 04:03:40.377855    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:03:40.378102    2337 trace.go:236] Trace[1977844723]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:03:30.289) (total time: 10088ms):
Trace[1977844723]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10088ms (04:03:40.377)
Trace[1977844723]: [10.088431747s] [10.088431747s] END
E0322 04:03:40.378231    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
W0322 04:03:42.578757    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
I0322 04:03:42.579047    2337 trace.go:236] Trace[1159587676]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:03:32.554) (total time: 10024ms):
Trace[1159587676]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout 10024ms (04:03:42.578)
Trace[1159587676]: [10.024442104s] [10.024442104s] END
E0322 04:03:42.579159    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
W0322 04:03:47.499187    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
I0322 04:03:47.499452    2337 trace.go:236] Trace[1385933293]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:03:37.497) (total time: 10001ms):
Trace[1385933293]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout 10001ms (04:03:47.499)
Trace[1385933293]: [10.001381036s] [10.001381036s] END
E0322 04:03:47.499546    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
time="2024-03-22T04:03:48Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
E0322 04:03:48.415245    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:03:49.062478    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
W0322 04:03:52.068039    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:03:52.068289    2337 trace.go:236] Trace[515962934]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:03:42.066) (total time: 10001ms):
Trace[515962934]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (04:03:52.068)
Trace[515962934]: [10.001866709s] [10.001866709s] END
E0322 04:03:52.068404    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:03:56.064494    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
E0322 04:03:57.034929    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": context deadline exceeded" interval="7s"
W0322 04:03:57.035006    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:03:58.417730    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:03:58.464398    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa4c0fa65", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
E0322 04:04:06.069400    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
E0322 04:04:08.424115    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
I0322 04:04:13.093561    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
time="2024-03-22T04:04:13Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
W0322 04:04:14.054324    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:04:14.054671    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)" interval="7s"
E0322 04:04:18.425795    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:04:18.470003    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa4c0fa65", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
W0322 04:04:21.405884    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:04:21.406170    2337 trace.go:236] Trace[1891282309]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:04:11.404) (total time: 10001ms):
Trace[1891282309]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (04:04:21.405)
Trace[1891282309]: [10.001551114s] [10.001551114s] END
E0322 04:04:21.406398    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
E0322 04:04:23.098185    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
W0322 04:04:27.446768    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
I0322 04:04:27.446888    2337 trace.go:236] Trace[1019818629]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:04:17.445) (total time: 10001ms):
Trace[1019818629]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout 10001ms (04:04:27.446)
Trace[1019818629]: [10.001682612s] [10.001682612s] END
E0322 04:04:27.446908    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Endpoints: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
E0322 04:04:28.426946    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
I0322 04:04:30.099446    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
E0322 04:04:31.057062    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": context deadline exceeded" interval="7s"
W0322 04:04:31.057494    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
W0322 04:04:31.190218    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:04:31.190331    2337 trace.go:236] Trace[297059082]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:04:21.188) (total time: 10001ms):
Trace[297059082]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10001ms (04:04:31.190)
Trace[297059082]: [10.001486953s] [10.001486953s] END
E0322 04:04:31.190348    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
W0322 04:04:36.649696    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:04:36.649751    2337 trace.go:236] Trace[868696851]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:04:26.648) (total time: 10000ms):
Trace[868696851]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout 10000ms (04:04:36.649)
Trace[868696851]: [10.000995592s] [10.000995592s] END
E0322 04:04:36.649764    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
time="2024-03-22T04:04:38Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
E0322 04:04:38.427102    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:04:38.489494    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa4c0fa65", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
E0322 04:04:40.105913    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
W0322 04:04:46.127438    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:04:46.127652    2337 trace.go:236] Trace[161423149]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:04:36.125) (total time: 10001ms):
Trace[161423149]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10001ms (04:04:46.127)
Trace[161423149]: [10.001847593s] [10.001847593s] END
E0322 04:04:46.127684    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:04:47.107787    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
W0322 04:04:47.591513    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
I0322 04:04:47.591772    2337 trace.go:236] Trace[509399403]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:04:37.590) (total time: 10001ms):
Trace[509399403]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout 10001ms (04:04:47.591)
Trace[509399403]: [10.001453903s] [10.001453903s] END
E0322 04:04:47.591885    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
W0322 04:04:47.785394    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
I0322 04:04:47.785501    2337 trace.go:236] Trace[27487769]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:04:37.782) (total time: 10003ms):
Trace[27487769]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout 10003ms (04:04:47.785)
Trace[27487769]: [10.003339526s] [10.003339526s] END
E0322 04:04:47.785518    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
E0322 04:04:48.060829    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": context deadline exceeded" interval="7s"
W0322 04:04:48.060878    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:04:48.428003    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:04:58.429003    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
time="2024-03-22T04:05:03Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
E0322 04:05:05.061572    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": context deadline exceeded" interval="7s"
E0322 04:05:08.430109    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:05:18.430765    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
W0322 04:05:22.063229    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:05:22.063389    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="7s"
time="2024-03-22T04:05:28Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
E0322 04:05:28.431219    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:05:38.431613    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
W0322 04:05:39.065430    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:05:39.066098    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="7s"
W0322 04:05:44.745833    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": http2: client connection lost
I0322 04:05:44.746121    2337 trace.go:236] Trace[514941232]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:05:06.829) (total time: 37916ms):
Trace[514941232]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": http2: client connection lost 37916ms (04:05:44.745)
Trace[514941232]: [37.916645591s] [37.916645591s] END
E0322 04:05:44.746459    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Endpoints: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": http2: client connection lost
E0322 04:05:48.432289    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
time="2024-03-22T04:05:53Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
W0322 04:05:56.113936    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:05:56.114216    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="7s"
E0322 04:05:58.433350    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:06:08.433911    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
W0322 04:06:13.118358    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:06:13.118780    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)" interval="7s"
time="2024-03-22T04:06:18Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
E0322 04:06:18.434995    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:06:28.437711    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
W0322 04:06:30.123094    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:06:30.123299    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled (Client.Timeout exceeded while awaiting headers)" interval="7s"
W0322 04:06:30.769368    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": http2: client connection lost
W0322 04:06:30.769440    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": http2: client connection lost
I0322 04:06:30.769553    2337 trace.go:236] Trace[2098489048]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:05:13.796) (total time: 76973ms):
Trace[2098489048]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": http2: client connection lost 76972ms (04:06:30.769)
Trace[2098489048]: [1m16.973100203s] [1m16.973100203s] END
I0322 04:06:30.769565    2337 trace.go:236] Trace[56389186]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:05:21.678) (total time: 69091ms):
Trace[56389186]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": http2: client connection lost 69091ms (04:06:30.769)
Trace[56389186]: [1m9.091319439s] [1m9.091319439s] END
E0322 04:06:30.769573    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": http2: client connection lost
E0322 04:06:30.769584    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": http2: client connection lost
W0322 04:06:30.769644    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": http2: client connection lost
E0322 04:06:30.769670    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": http2: client connection lost" node="serverworker"
I0322 04:06:30.769723    2337 trace.go:236] Trace[1389590667]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:05:15.504) (total time: 75265ms):
Trace[1389590667]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": http2: client connection lost 75265ms (04:06:30.769)
Trace[1389590667]: [1m15.265225514s] [1m15.265225514s] END
E0322 04:06:30.769737    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": http2: client connection lost
W0322 04:06:30.769730    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": http2: client connection lost
I0322 04:06:30.769778    2337 trace.go:236] Trace[397774737]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:05:47.234) (total time: 43535ms):
Trace[397774737]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": http2: client connection lost 43535ms (04:06:30.769)
Trace[397774737]: [43.535335219s] [43.535335219s] END
E0322 04:06:30.769812    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": http2: client connection lost
E0322 04:06:30.769897    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa4c0fa65", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": http2: client connection lost'(may retry after sleeping)
E0322 04:06:30.770223    2337 event.go:228] Unable to write event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa4c0fa65", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 226524773, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}' (retry limit exceeded!)
W0322 04:06:30.770385    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": http2: client connection lost
I0322 04:06:30.770495    2337 trace.go:236] Trace[1850847198]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:05:15.092) (total time: 75677ms):
Trace[1850847198]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": http2: client connection lost 75677ms (04:06:30.770)
Trace[1850847198]: [1m15.677876017s] [1m15.677876017s] END
E0322 04:06:30.770510    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": http2: client connection lost
W0322 04:06:30.770594    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": http2: client connection lost
I0322 04:06:30.770641    2337 trace.go:236] Trace[1868476760]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:05:20.354) (total time: 70415ms):
Trace[1868476760]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": http2: client connection lost 70415ms (04:06:30.770)
Trace[1868476760]: [1m10.415959385s] [1m10.415959385s] END
E0322 04:06:30.770688    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": http2: client connection lost
I0322 04:06:37.771885    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
E0322 04:06:38.438818    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
W0322 04:06:39.779955    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
I0322 04:06:39.780244    2337 trace.go:236] Trace[532748410]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:06:29.778) (total time: 10001ms):
Trace[532748410]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout 10001ms (04:06:39.779)
Trace[532748410]: [10.001539861s] [10.001539861s] END
E0322 04:06:39.780419    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Endpoints: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
E0322 04:06:40.771345    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa5417d78", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"InvalidDiskCapacity", Message:"invalid capacity 0 on image filesystem", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 234946936, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 234946936, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
W0322 04:06:42.265007    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:06:42.265395    2337 trace.go:236] Trace[893989490]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:06:32.263) (total time: 10002ms):
Trace[893989490]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (04:06:42.264)
Trace[893989490]: [10.002200948s] [10.002200948s] END
E0322 04:06:42.265531    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
time="2024-03-22T04:06:43Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
W0322 04:06:47.123897    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:06:47.124053    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)" interval="7s"
E0322 04:06:47.784080    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
E0322 04:06:48.444394    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
I0322 04:06:54.785340    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
W0322 04:06:54.927547    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:06:54.928066    2337 trace.go:236] Trace[1461482815]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:06:44.925) (total time: 10002ms):
Trace[1461482815]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (04:06:54.927)
Trace[1461482815]: [10.002457348s] [10.002457348s] END
E0322 04:06:54.928279    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
E0322 04:06:58.444760    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:06:58.675704    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa5417d78", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"InvalidDiskCapacity", Message:"invalid capacity 0 on image filesystem", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 234946936, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 234946936, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
E0322 04:07:04.125067    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": context deadline exceeded" interval="7s"
W0322 04:07:04.125210    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:07:04.786989    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
time="2024-03-22T04:07:08Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
E0322 04:07:08.445110    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
W0322 04:07:10.936649    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:07:10.936968    2337 trace.go:236] Trace[427282545]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:07:00.935) (total time: 10001ms):
Trace[427282545]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (04:07:10.936)
Trace[427282545]: [10.001358022s] [10.001358022s] END
E0322 04:07:10.937134    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0322 04:07:11.261947    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:07:11.262323    2337 trace.go:236] Trace[1226612255]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:07:01.260) (total time: 10001ms):
Trace[1226612255]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10001ms (04:07:11.261)
Trace[1226612255]: [10.00165414s] [10.00165414s] END
E0322 04:07:11.262415    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:07:11.788594    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
W0322 04:07:14.180036    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
I0322 04:07:14.180228    2337 trace.go:236] Trace[1095395271]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:07:03.910) (total time: 10269ms):
Trace[1095395271]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout 10269ms (04:07:14.180)
Trace[1095395271]: [10.26945241s] [10.26945241s] END
E0322 04:07:14.180324    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://127.0.0.1:6444/api/v1/nodes?fieldSelector=metadata.name%3Dserverworker&resourceVersion=700": net/http: TLS handshake timeout
E0322 04:07:18.445826    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:07:18.686193    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa5417d78", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"InvalidDiskCapacity", Message:"invalid capacity 0 on image filesystem", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 234946936, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 234946936, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
W0322 04:07:21.126615    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:07:21.127067    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)" interval="7s"
W0322 04:07:21.687911    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
I0322 04:07:21.688202    2337 trace.go:236] Trace[1190702877]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:07:11.686) (total time: 10001ms):
Trace[1190702877]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout 10001ms (04:07:21.687)
Trace[1190702877]: [10.001855364s] [10.001855364s] END
E0322 04:07:21.688342    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://127.0.0.1:6444/api/v1/services?resourceVersion=756": net/http: TLS handshake timeout
E0322 04:07:21.789409    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
W0322 04:07:22.293299    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
I0322 04:07:22.293672    2337 trace.go:236] Trace[842004954]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:07:12.289) (total time: 10004ms):
Trace[842004954]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout 10004ms (04:07:22.293)
Trace[842004954]: [10.004281939s] [10.004281939s] END
E0322 04:07:22.293865    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://127.0.0.1:6444/apis/storage.k8s.io/v1/csidrivers?resourceVersion=704": net/http: TLS handshake timeout
W0322 04:07:24.701336    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:07:24.701486    2337 trace.go:236] Trace[63714171]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:07:14.698) (total time: 10002ms):
Trace[63714171]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout 10002ms (04:07:24.701)
Trace[63714171]: [10.002489184s] [10.002489184s] END
E0322 04:07:24.701513    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://127.0.0.1:6444/api/v1/pods?fieldSelector=spec.nodeName%3Dserverworker&limit=500&resourceVersion=0": net/http: TLS handshake timeout
W0322 04:07:27.425614    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
I0322 04:07:27.426237    2337 trace.go:236] Trace[1705797067]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:07:17.424) (total time: 10002ms):
Trace[1705797067]: ---"Objects listed" error:Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout 10001ms (04:07:27.425)
Trace[1705797067]: [10.002021324s] [10.002021324s] END
E0322 04:07:27.426392    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: Get "https://127.0.0.1:6444/apis/node.k8s.io/v1/runtimeclasses?limit=500&resourceVersion=0": net/http: TLS handshake timeout
E0322 04:07:28.446468    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
I0322 04:07:28.793747    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
W0322 04:07:30.323992    2337 reflector.go:535] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
I0322 04:07:30.324109    2337 trace.go:236] Trace[2067049199]: "Reflector ListAndWatch" name:k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229 (22-Mar-2024 04:07:20.322) (total time: 10001ms):
Trace[2067049199]: ---"Objects listed" error:Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout 10001ms (04:07:30.323)
Trace[2067049199]: [10.001763237s] [10.001763237s] END
E0322 04:07:30.324165    2337 reflector.go:147] k8s.io/client-go@v1.28.7-k3s1/tools/cache/reflector.go:229: Failed to watch *v1.Endpoints: failed to list *v1.Endpoints: Get "https://127.0.0.1:6444/api/v1/namespaces/default/endpoints?fieldSelector=metadata.name%3Dkubernetes&resourceVersion=713": net/http: TLS handshake timeout
time="2024-03-22T04:07:33Z" level=info msg="Waiting to retrieve kube-proxy configuration; server is not ready: failed to get CA certs: Get \"https://127.0.0.1:6444/cacerts\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
W0322 04:07:38.129001    2337 transport.go:301] Unable to cancel request for *otelhttp.Transport
E0322 04:07:38.129146    2337 controller.go:146] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6444/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/serverworker?timeout=10s\": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)" interval="7s"
E0322 04:07:38.447280    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
E0322 04:07:38.753133    2337 event.go:289] Unable to write event: '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"serverworker.17befa3aa5417d78", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"serverworker", UID:"serverworker", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"InvalidDiskCapacity", Message:"invalid capacity 0 on image filesystem", Source:v1.EventSource{Component:"kubelet", Host:"serverworker"}, FirstTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 234946936, time.Local), LastTimestamp:time.Date(2024, time.March, 22, 4, 0, 38, 234946936, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"kubelet", ReportingInstance:"serverworker"}': 'Post "https://127.0.0.1:6444/api/v1/namespaces/default/events": net/http: TLS handshake timeout'(may retry after sleeping)
E0322 04:07:38.795888    2337 kubelet_node_status.go:92] "Unable to register node with API server" err="Post \"https://127.0.0.1:6444/api/v1/nodes\": net/http: TLS handshake timeout" node="serverworker"
time="2024-03-22T04:07:43Z" level=info msg="Running kube-proxy --cluster-cidr=10.42.0.0/16 --conntrack-max-per-core=0 --conntrack-tcp-timeout-close-wait=0s --conntrack-tcp-timeout-established=0s --healthz-bind-address=127.0.0.1 --hostname-override=serverworker --kubeconfig=/var/lib/rancher/k3s/agent/kubeproxy.kubeconfig --proxy-mode=iptables"
I0322 04:07:45.846468    2337 kubelet_node_status.go:70] "Attempting to register node" node="serverworker"
E0322 04:07:47.545863    2337 nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"serverworker\" not found" node="serverworker"
I0322 04:07:47.546009    2337 kubelet_node_status.go:73] "Successfully registered node" node="serverworker"
E0322 04:07:47.545878    2337 node.go:130] Failed to retrieve node info: nodes "serverworker" not found
E0322 04:07:47.558183    2337 kubelet_node_status.go:540] "Error updating node status, will retry" err="error getting node \"serverworker\": nodes \"serverworker\" not found"
E0322 04:07:47.840453    2337 kubelet_node_status.go:458] "Error getting the current node from lister" err="node \"serverworker\" not found"
E0322 04:07:47.941483    2337 kubelet_node_status.go:452] "Node not becoming ready in time after startup"
E0322 04:07:48.448028    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
I0322 04:07:48.609018    2337 node.go:141] Successfully retrieved node IP: 192.168.56.111
I0322 04:07:48.616665    2337 server.go:632] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0322 04:07:48.620261    2337 server_others.go:152] "Using iptables Proxier"
I0322 04:07:48.620319    2337 server_others.go:421] "Detect-local-mode set to ClusterCIDR, but no cluster CIDR for family" ipFamily="IPv6"
I0322 04:07:48.620372    2337 server_others.go:438] "Defaulting to no-op detect-local"
I0322 04:07:48.620403    2337 proxier.go:250] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0322 04:07:48.620627    2337 server.go:846] "Version info" version="v1.28.7+k3s1"
I0322 04:07:48.620647    2337 server.go:848] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0322 04:07:48.625280    2337 config.go:188] "Starting service config controller"
I0322 04:07:48.625319    2337 shared_informer.go:311] Waiting for caches to sync for service config
I0322 04:07:48.625365    2337 config.go:97] "Starting endpoint slice config controller"
I0322 04:07:48.625392    2337 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0322 04:07:48.626187    2337 config.go:315] "Starting node config controller"
I0322 04:07:48.626214    2337 shared_informer.go:311] Waiting for caches to sync for node config
I0322 04:07:48.725506    2337 shared_informer.go:318] Caches are synced for endpoint slice config
I0322 04:07:48.725580    2337 shared_informer.go:318] Caches are synced for service config
I0322 04:07:48.726250    2337 shared_informer.go:318] Caches are synced for node config
E0322 04:07:48.952748    2337 resource_metrics.go:152] "Error getting summary for resourceMetric prometheus endpoint" err="failed to get node info: node \"serverworker\" not found"
I0322 04:07:58.054818    2337 kuberuntime_manager.go:1528] "Updating runtime config through cri with podcidr" CIDR="10.42.1.0/24"
I0322 04:07:58.056136    2337 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.42.1.0/24"
time="2024-03-22T04:07:58Z" level=info msg="Tunnel authorizer set Kubelet Port 10250"
E0322 04:07:58.482787    2337 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"serverworker\" not found"
time="2024-03-22T04:08:00Z" level=info msg="Annotations and labels have been set successfully on node: serverworker"
time="2024-03-22T04:08:00Z" level=info msg="Starting flannel with backend vxlan"
time="2024-03-22T04:08:00Z" level=info msg="Flannel found PodCIDR assigned for node serverworker"
time="2024-03-22T04:08:00Z" level=info msg="The interface enp0s3 with ipv4 address 10.0.2.15 will be used by flannel"
I0322 04:08:00.276777    2337 kube.go:139] Waiting 10m0s for node controller to sync
I0322 04:08:00.276818    2337 kube.go:461] Starting kube subnet manager
I0322 04:08:00.287211    2337 kube.go:482] Creating the node lease for IPv4. This is the n.Spec.PodCIDRs: [10.42.0.0/24]
time="2024-03-22T04:08:00Z" level=info msg="Starting network policy controller version v2.0.1, built on 2024-02-29T20:36:21Z, go1.21.7"
I0322 04:08:00.405943    2337 network_policy_controller.go:164] Starting network policy controller
I0322 04:08:00.455682    2337 network_policy_controller.go:176] Starting network policy controller full sync goroutine
I0322 04:08:01.278027    2337 kube.go:146] Node controller sync successful
I0322 04:08:01.278319    2337 vxlan.go:141] VXLAN config: VNI=1 Port=0 GBP=false Learning=false DirectRouting=false
I0322 04:08:01.282872    2337 kube.go:621] List of node(serverworker) annotations: map[string]string{"alpha.kubernetes.io/provided-node-ip":"192.168.56.111", "k3s.io/hostname":"serverworker", "k3s.io/internal-ip":"192.168.56.111", "k3s.io/node-args":"[\"agent\",\"--server\",\"https://192.168.56.110:6443\",\"--token-file\",\"/vagrant/provision/token\",\"--node-ip\",\"192.168.56.111\",\"--log\",\"/vagrant/logs/agent.logs\"]", "k3s.io/node-config-hash":"YEJVE25BLELMUPKU6DR5NCCNF5THAXBIIU55LWYRIMCEB5QXNKOA====", "k3s.io/node-env":"{\"K3S_DATA_DIR\":\"/var/lib/rancher/k3s/data/a3b46c0299091b71bfcc617b1e1fec1845c13bdd848584ceb39d2e700e702a4b\"}", "node.alpha.kubernetes.io/ttl":"0", "volumes.kubernetes.io/controller-managed-attach-detach":"true"}
I0322 04:08:01.320028    2337 kube.go:482] Creating the node lease for IPv4. This is the n.Spec.PodCIDRs: [10.42.1.0/24]
time="2024-03-22T04:08:01Z" level=info msg="Wrote flannel subnet file to /run/flannel/subnet.env"
time="2024-03-22T04:08:01Z" level=info msg="Running flannel backend."
I0322 04:08:01.332027    2337 vxlan_network.go:65] watching for new subnet leases
I0322 04:08:01.332082    2337 subnet.go:160] Batch elem [0] is { lease.Event{Type:0, Lease:lease.Lease{EnableIPv4:true, EnableIPv6:false, Subnet:ip.IP4Net{IP:0xa2a0000, PrefixLen:0x18}, IPv6Subnet:ip.IP6Net{IP:(*ip.IP6)(nil), PrefixLen:0x0}, Attrs:lease.LeaseAttrs{PublicIP:0xa00020f, PublicIPv6:(*ip.IP6)(nil), BackendType:"vxlan", BackendData:json.RawMessage{0x7b, 0x22, 0x56, 0x4e, 0x49, 0x22, 0x3a, 0x31, 0x2c, 0x22, 0x56, 0x74, 0x65, 0x70, 0x4d, 0x41, 0x43, 0x22, 0x3a, 0x22, 0x34, 0x32, 0x3a, 0x66, 0x30, 0x3a, 0x63, 0x65, 0x3a, 0x37, 0x36, 0x3a, 0x65, 0x64, 0x3a, 0x34, 0x35, 0x22, 0x7d}, BackendV6Data:json.RawMessage(nil)}, Expiration:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Asof:0}} }
I0322 04:08:01.332230    2337 iptables.go:290] generated 3 rules
I0322 04:08:01.333774    2337 iptables.go:290] generated 7 rules
I0322 04:08:01.347377    2337 iptables.go:283] bootstrap done
I0322 04:08:01.361015    2337 iptables.go:283] bootstrap done
I0322 04:08:02.399439    2337 topology_manager.go:215] "Topology Admit Handler" podUID="508d3083-0439-467e-987f-c94af1320b1f" podNamespace="kube-system" podName="svclb-traefik-2c133370-gbs2d"
I0322 04:08:02.435304    2337 desired_state_of_world_populator.go:159] "Finished populating initial desired state of world"
I0322 04:08:09.250171    2337 kuberuntime_container_linux.go:167] "No swap cgroup controller present" swapBehavior="" pod="kube-system/svclb-traefik-2c133370-gbs2d" containerName="lb-tcp-80"
I0322 04:08:09.395625    2337 kuberuntime_container_linux.go:167] "No swap cgroup controller present" swapBehavior="" pod="kube-system/svclb-traefik-2c133370-gbs2d" containerName="lb-tcp-443"
I0322 04:08:10.152385    2337 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/svclb-traefik-2c133370-gbs2d" podStartSLOduration=6.474978997 podCreationTimestamp="2024-03-22 04:08:00 +0000 UTC" firstStartedPulling="2024-03-22 04:08:05.569881843 +0000 UTC m=+785.896211494" lastFinishedPulling="2024-03-22 04:08:09.247203444 +0000 UTC m=+789.573533113" observedRunningTime="2024-03-22 04:08:10.152044161 +0000 UTC m=+790.478373832" watchObservedRunningTime="2024-03-22 04:08:10.152300616 +0000 UTC m=+790.478630295"
time="2024-03-23T01:33:53Z" level=info msg="Starting k3s agent v1.28.7+k3s1 (051b14b2)"
time="2024-03-23T01:33:53Z" level=info msg="Adding server to load balancer k3s-agent-load-balancer: 192.168.56.110:6443"
time="2024-03-23T01:33:53Z" level=info msg="Running load balancer k3s-agent-load-balancer 127.0.0.1:6444 -> [192.168.56.110:6443] [default: 192.168.56.110:6443]"
time="2024-03-23T01:33:53Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:34:01Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:34:10Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:34:19Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:34:26Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:34:35Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:34:45Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:34:54Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:35:02Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:35:10Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:35:19Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:35:28Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:35:36Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:35:42Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:35:48Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:35:54Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:36:00Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-23T01:36:06Z" level=info msg="Waiting to retrieve agent configuration; server is not ready: Node password rejected, duplicate hostname or contents of '/etc/rancher/node/password' may not match server node-passwd entry, try enabling a unique node name with the --with-node-id flag"
time="2024-03-27T14:21:14Z" level=info msg="Starting k3s agent v1.28.7+k3s1 (051b14b2)"
time="2024-03-27T14:21:14Z" level=info msg="Adding server to load balancer k3s-agent-load-balancer: 192.168.56.110:6443"
time="2024-03-27T14:21:14Z" level=info msg="Running load balancer k3s-agent-load-balancer 127.0.0.1:6444 -> [192.168.56.110:6443] [default: 192.168.56.110:6443]"
time="2024-03-27T14:21:14Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:16Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:18Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:20Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:22Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:24Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:27Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:29Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:31Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:33Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:35Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:37Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:39Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:41Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:43Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:45Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:47Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:49Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:51Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:53Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:55Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:57Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:21:59Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:01Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:03Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:05Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:07Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:09Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:11Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:13Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:15Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:17Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:19Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:21Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:23Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:25Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:27Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:29Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:31Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:33Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:35Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:37Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:39Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:41Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:44Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:46Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:48Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:50Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:52Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:54Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:56Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:22:58Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:00Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:02Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:04Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:06Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:08Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:10Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:12Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:14Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:16Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:18Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:20Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:22Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:24Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:26Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:28Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:30Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:32Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:35Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:37Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:39Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:41Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:43Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:45Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:47Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:49Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:51Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:53Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:55Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:57Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:23:59Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:01Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:03Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:05Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:07Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:09Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:11Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:13Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:15Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:17Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:19Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:21Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:23Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:25Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:27Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:29Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:31Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:33Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:35Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:37Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:39Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:41Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:43Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:45Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:47Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:49Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:51Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:53Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:55Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:57Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:24:59Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:02Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:04Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:06Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:08Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:10Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:12Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:14Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:16Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:18Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:20Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:22Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:24Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:26Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:28Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:30Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:32Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:34Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:36Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:38Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:40Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:42Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:44Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:46Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:48Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:50Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:52Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:54Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:56Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:25:58Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:00Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:02Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:04Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:06Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:08Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:10Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:12Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:14Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:16Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:18Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:20Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:23Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:25Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:27Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:29Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:31Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:33Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:35Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:37Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:39Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:41Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:43Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:45Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:47Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:49Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:51Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:53Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:55Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:57Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:26:59Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:01Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:03Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:05Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:07Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:09Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:11Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:13Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:15Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:17Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:19Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:21Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:23Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:25Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:27Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:29Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:31Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:33Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:35Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:37Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:39Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:41Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:43Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:46Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:48Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:50Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:52Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:54Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:56Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:27:58Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:28:00Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:28:02Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:28:04Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:28:06Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:28:08Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:28:10Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:28:12Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:28:14Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:28:16Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
time="2024-03-27T14:28:18Z" level=error msg="token CA hash does not match the Cluster CA certificate hash: 2796f61a17b2599cdbaf6668cc515e9e1aae574c83acfa28f7c85ef9b072f079 != e6eea3597e398c3c5b10a620c16bbb1eb103cea683e370216161a5f057e2d1fb"
